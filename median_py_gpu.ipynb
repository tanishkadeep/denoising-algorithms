{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pynvml GPUtil"
      ],
      "metadata": {
        "id": "reVJAEQVzbAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import os\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "\n",
        "base_path = \"/content/drive/My Drive/dataset\"\n",
        "\n",
        "def median_filter_gpu(image_tensor, ksize=5):\n",
        "    if ksize % 2 == 0:\n",
        "        ksize += 1\n",
        "\n",
        "    image_np = image_tensor.permute(1, 2, 0).cpu().numpy()\n",
        "    image_np = (image_np * 255).astype(np.uint8)\n",
        "    filtered_image_np = cv2.medianBlur(image_np, ksize)\n",
        "    filtered_image_tensor = torch.tensor(filtered_image_np, dtype=torch.float32).permute(2, 0, 1).cuda()\n",
        "    filtered_image_tensor = filtered_image_tensor / 255.0\n",
        "    return filtered_image_tensor\n",
        "\n",
        "def measure_metrics(image, filtered_image, inference_time):\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory_allocated = torch.cuda.memory_allocated() / (1024 * 1024)\n",
        "    gpu_memory_reserved = torch.cuda.memory_reserved() / (1024 * 1024)\n",
        "    gpu_load = torch.cuda.utilization(0)\n",
        "    gpu_temperature = torch.cuda.temperature(0)\n",
        "    psnr_value = psnr(image, filtered_image)\n",
        "\n",
        "    metrics = {\n",
        "        \"GPU\": gpu_name,\n",
        "        \"GPU Memory Usage (MB)\": f\"{gpu_memory_allocated:.2f} MB / {gpu_memory_reserved:.2f} MB\",\n",
        "        \"GPU Load (%)\": gpu_load,\n",
        "        \"Temperature (°C)\": gpu_temperature,\n",
        "        \"Inference Time (ms)\": inference_time,\n",
        "        \"PSNR (dB)\": psnr_value,\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def process_image(image_path, output_path, ksize=5):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "    if image.shape[0] > 720 or image.shape[1] > 1280:\n",
        "        raise ValueError(\"Image size exceeds the allowed dimensions of 1280x720p\")\n",
        "\n",
        "    image_tensor = torch.tensor(image, dtype=torch.float32).cuda()\n",
        "    if len(image_tensor.shape) == 2:\n",
        "        image_tensor = image_tensor.unsqueeze(0)\n",
        "    else:\n",
        "        image_tensor = image_tensor.permute(2, 0, 1)\n",
        "\n",
        "    image_tensor = image_tensor / 255.0\n",
        "\n",
        "    start_time = time.time()\n",
        "    filtered_image_tensor = median_filter_gpu(image_tensor, ksize=ksize)\n",
        "    inference_time = (time.time() - start_time) * 1000\n",
        "\n",
        "    filtered_image = filtered_image_tensor.cpu().numpy()\n",
        "    if len(filtered_image.shape) == 3:\n",
        "        filtered_image = np.moveaxis(filtered_image, 0, -1)\n",
        "    else:\n",
        "        filtered_image = filtered_image.squeeze()\n",
        "    filtered_image = (filtered_image * 255).astype(np.uint8)\n",
        "\n",
        "    metrics = measure_metrics(image, filtered_image, inference_time)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def process_all_images_in_all_folders(folders, ksize=5):\n",
        "    total_metrics = {\n",
        "        \"GPU\": None,\n",
        "        \"GPU Memory Usage (MB)\": \"0.00 MB / 0.00 MB\",\n",
        "        \"GPU Load (%)\": 0,\n",
        "        \"Temperature (°C)\": 0,\n",
        "        \"Inference Time (ms)\": 0,\n",
        "        \"PSNR (dB)\": 0,\n",
        "    }\n",
        "\n",
        "    total_images = 0\n",
        "    total_time_start = time.time()\n",
        "\n",
        "    for noisy_folder, denoised_folder in folders.items():\n",
        "        input_folder = os.path.join(base_path, noisy_folder)\n",
        "        output_folder = os.path.join(base_path, denoised_folder)\n",
        "\n",
        "        if not os.path.exists(output_folder):\n",
        "            os.makedirs(output_folder)\n",
        "\n",
        "        image_files = [f for f in os.listdir(input_folder) if os.path.isfile(os.path.join(input_folder, f))]\n",
        "\n",
        "        total_images += len(image_files)\n",
        "\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(input_folder, image_file)\n",
        "            output_path = os.path.join(output_folder, image_file)\n",
        "\n",
        "            metrics = process_image(image_path, output_path, ksize)\n",
        "\n",
        "            total_metrics[\"Inference Time (ms)\"] += metrics[\"Inference Time (ms)\"]\n",
        "            total_metrics[\"PSNR (dB)\"] += metrics[\"PSNR (dB)\"]\n",
        "            total_metrics[\"GPU\"] = metrics[\"GPU\"]\n",
        "            total_metrics[\"GPU Memory Usage (MB)\"] = metrics[\"GPU Memory Usage (MB)\"]\n",
        "            total_metrics[\"GPU Load (%)\"] += metrics[\"GPU Load (%)\"]\n",
        "            total_metrics[\"Temperature (°C)\"] += metrics[\"Temperature (°C)\"]\n",
        "\n",
        "    total_time_end = time.time()\n",
        "    total_time_taken = (total_time_end - total_time_start) * 1000\n",
        "\n",
        "    if total_images > 0:\n",
        "        avg_inference_time = total_metrics[\"Inference Time (ms)\"] / total_images\n",
        "        avg_gpu_load = total_metrics[\"GPU Load (%)\"] / total_images\n",
        "        avg_temperature = total_metrics[\"Temperature (°C)\"] / total_images\n",
        "        avg_psnr = total_metrics[\"PSNR (dB)\"] / total_images\n",
        "\n",
        "        total_metrics[\"Inference Time (ms)\"] = avg_inference_time\n",
        "        total_metrics[\"GPU Load (%)\"] = avg_gpu_load\n",
        "        total_metrics[\"Temperature (°C)\"] = avg_temperature\n",
        "        total_metrics[\"PSNR (dB)\"] = avg_psnr\n",
        "\n",
        "    print(\"Final Metrics Summary:\")\n",
        "    for metric, value in total_metrics.items():\n",
        "        print(f\"{metric}: {value}\")\n",
        "    print(f\"Total Time Taken (ms): {total_time_taken:.2f}\")\n",
        "    print(f\"Average Inference Time per Image (ms): {avg_inference_time:.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    folders = {\n",
        "        \"noisy5\": \"denoised5\",\n",
        "        \"noisy15\": \"denoised15\",\n",
        "        \"noisy35\": \"denoised35\"\n",
        "    }\n",
        "\n",
        "    process_all_images_in_all_folders(folders, ksize=5)\n"
      ],
      "metadata": {
        "id": "Meyx0rqtz0iJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}